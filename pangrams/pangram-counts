#!/usr/bin/python3
# Copyright (C) 2024 Dez Moleski dez@moleski.com
# MIT License: All uses allowed with attribution.
#
from wordgames import Word, WordList, AnagramsDict, LetterSetBitmask, ALPHABET_LIST
import sys
from copy import deepcopy
from glob import glob
import datetime
import json
import os.path

if __name__ == "__main__":
   if len(sys.argv) != 1:
      exit("Usage: pangram-counts")
   
   # Read ALL GUESSES file
   ALL_FILE = "./ALL"
   print("Reading all valid guesses file:", ALL_FILE, file=sys.stderr, flush=True, end=' ')
   valid_guesses = WordList.from_file(ALL_FILE)
   valid_guesses.sort()
   print("N =", len(valid_guesses), file=sys.stderr, flush=True)
   
   # Read ANSWERS
   ANSWERS_FILE = "./ANSWERS"
   print("Reading answers file:", ANSWERS_FILE, file=sys.stderr, flush=True, end=' ')
   answers = WordList.from_file(ANSWERS_FILE)
   answers.sort()
   print("N =", len(answers), file=sys.stderr, flush=True)

   # Read WORD-PERCENT list and build up the word_percent dict.
   # We only need to keep individual items for words starting
   # with letters less than our "done from here on..." letter.
   DONE_FROM_LETTER = 'H'
   word_percent = dict()
   WORD_PERCENT_FILE = "./WORD-PERCENT"
   done_percent = 0.0
   print("Done from", DONE_FROM_LETTER, "to Z, percent = ", file=sys.stderr, flush=True, end='')
   if os.path.isfile(WORD_PERCENT_FILE):
      with open(WORD_PERCENT_FILE) as f:
         for word_percent_line in f:
            wp = word_percent_line.split()
            word = wp[0]
            percent = float(wp[1])
            if word[0] < DONE_FROM_LETTER:
               word_percent[word] = percent
            else:
               done_percent += percent
   print(f'{done_percent:.2f}%', file=sys.stderr, flush=True)
   
   # Visit each pangram data file
   print("Scanning data files: ", file=sys.stderr, flush=True, end='')
   all_pgrams = list()
   all_words = WordList()
   answers_used = WordList()
   total_pangrams = 0
   n_word_percents_counted = 0
   current_head_word = None
   count_this_head_word = 0
   max_head_word = None
   max_head_word_count = 0
   word_count = dict()
   anagrams = set()
   for letter in ALPHABET_LIST:
      print(letter, file=sys.stderr, flush=True, end=' ')
      datadir = f"./data/{letter}/"
      if os.path.isdir(datadir):
         # Visit each file in the data dir
         paths = sorted(glob(datadir+'*'))
         for filepath in paths:
            with open(filepath, 'r') as f:
               # Read each line and split first into line_list array.
               # Anagrams within the line are like: '[VIGOR|VIRGO]'
               for line in f:
                  line_list = line.split()
                  if line_list[0] == '#':
                     # For lines that start with '#', get the key word
                     # which is either by itself, or the first word of
                     # an anagram set like '[VIRGO|VIGOR]'
                     word_or_anagram = line_list[1]
                     if word_or_anagram[0] == '[':
                        word = word_or_anagram[1:6]
                     else:
                        word = word_or_anagram
                     if word[0] < DONE_FROM_LETTER:
                        done_percent += word_percent[word]
                        n_word_percents_counted += 1
                  else:
                     all_pgrams.append(line_list) # unexpanded anagrams here
                     
                     # Check if this is a new head word. If it is, note it,
                     # check for a new max, and reset our counter for this head word.
                     if line_list[0] != current_head_word:
                        if count_this_head_word > max_head_word_count:
                           max_head_word_count = count_this_head_word
                           max_head_word = current_head_word
                        current_head_word = line_list[0]
                        count_this_head_word = 0
                     
                     # Visit each word or anagram set in the line, and
                     # accumulate the words into our all_words WordList.
                     # Also count how many pangrams are generated by expanding any anagrams.
                     count_this_pangram = 1
                     single_words_in_this_pangram = list()
                     for item in line_list:
                        # If it's five letters, this item is a single word
                        if len(item) == 5:
                           single_words_in_this_pangram.append(item)
                           # Note duplicated code below; this should really be a function or otherwise refactored!
                           # We don't need to look at a word again after we've seen it one time.
                           if not all_words.contains(item):
                              all_words.add_str(item)
                              if answers.contains(item):
                                 answers_used.add_str(item)
                        else:
                           # It's anagrams like '[VIGOR|VIRGO]', so trim and split it into words.
                           stripped = item.strip('[]')
                           words = stripped.split('|')
                           # TODO: BUG? what about incrementing word_count for anagrams other than the first one?
                           # Also, if there are anagram sets other than this one, then this word actually appears
                           # in some number of pangrams more than one. This is tricky to fix...
                           word_count[words[0]] = word_count.get(words[0], 0) + 1
                           count_this_pangram *= len(words)
                           for w in words:
                              anagrams.add(w)
                              # Note duplicated code above; this should really be a function or otherwise refactored!
                              # We don't need to look at a word again after we've seen it one time.
                              if not all_words.contains(w):
                                 all_words.add_str(w)
                                 if answers.contains(w):
                                    answers_used.add_str(w)
                     count_this_head_word += count_this_pangram
                     total_pangrams += count_this_pangram
                     # Single words in this pangram that are NOT in anagram sets
                     # must have their word_count incremented by count_this_pangram
                     for item in single_words_in_this_pangram:
                        word_count[item] = word_count.get(item, 0) + count_this_pangram
                        
   print('', file=sys.stderr, flush=True)
   
   print("N base pangrams:", len(all_pgrams), file=sys.stderr, flush=True)
   print("N expanded pangrams:", total_pangrams, file=sys.stderr, flush=True)
   percent = len(all_words) / len(valid_guesses)
   print(f"N words used: {len(all_words)} / {len(valid_guesses)} = {percent:.0%}", file=sys.stderr, flush=True)
   percent = len(answers_used) / len(answers)
   print(f"N answers used: {len(answers_used)} / {len(answers)} = {percent:.0%}", file=sys.stderr, flush=True)
   print(f'Overall done = {done_percent:.2f}% ({n_word_percents_counted} words before letter {DONE_FROM_LETTER})',
         file=sys.stderr, flush=True)
   print(f'Max head word = {max_head_word}, with {max_head_word_count} pangrams.', file=sys.stderr, flush=True)
   
   print("Top words found in pangrams:", file=sys.stderr, flush=True)
   # Sort the (word,count) tuples in the word_count dict by count, highest to lowest, and slice off the top N
   l = sorted(word_count.items(), key=lambda t: t[1], reverse=True)[0:100]
   for t in l:
      percent = t[1] / total_pangrams
      print(f'1. `{t[0]}` : {t[1]} ({percent:.0%}) ', file=sys.stderr, flush=True, end='')
      if t[0] in anagrams:
         print('*', file=sys.stderr, flush=True)
      else:
         print('', file=sys.stderr, flush=True)
